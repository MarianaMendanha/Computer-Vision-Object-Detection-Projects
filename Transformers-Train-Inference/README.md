# ğŸ¯ Transformers-Train-Inference

Bem-vindo ao **Transformers-Train-Inference**, um projeto voltado para o treinamento e inferÃªncia de modelos de **DetecÃ§Ã£o de Objetos** utilizando **Transformers**! Aqui, vocÃª encontrarÃ¡ tudo o que precisa para treinar seu prÃ³prio modelo e realizar inferÃªncia em tempo real com imagens ou streams de cÃ¢mera IP.

## ğŸ“‚ Estrutura do Projeto

```bash
Transformers-Train-Inference
â”œâ”€â”€ README.md                 
â”œâ”€â”€ inference                 # CÃ³digo de inferÃªncia
â”‚   â”œâ”€â”€ cameraIP_RealTime.py   # InferÃªncia em tempo real com cÃ¢mera IP
â”‚   â”œâ”€â”€ output.mp4             # Exemplo de saÃ­da de inferÃªncia em vÃ­deo
â”‚   â”œâ”€â”€ requirements.txt       # DependÃªncias da inferÃªncia
â”‚   â””â”€â”€ testImage_camIP.py      # InferÃªncia de imagem estÃ¡tica
â””â”€â”€ train                     # CÃ³digo de treinamento
    â”œâ”€â”€ code-references        # ReferÃªncias para cÃ³digo de treinamento
    â”‚   â”œâ”€â”€ CÃ³pia_de_object_detection.ipynb
    â”‚   â””â”€â”€ run_object_detection.py
    â”œâ”€â”€ datasets               # Datasets de treinamento (detecÃ§Ã£o de EPI)
    â”‚   â”œâ”€â”€ Construction-Site-Safety-28
    â”‚   â”œâ”€â”€ cppe5
    â”‚   â””â”€â”€ PPEv5-17
    â”œâ”€â”€ models                 # Modelos treinados
    â”‚   â”œâ”€â”€ detr-finetuned-ppe
    â”‚   â””â”€â”€ modelo-treinado-1epoch
    â”œâ”€â”€ info.md                # InformaÃ§Ãµes sobre o treinamento
    â”œâ”€â”€ requirements.txt       # DependÃªncias do treinamento
    â”œâ”€â”€ test-trainedModel.py   # Teste do modelo treinado
    â””â”€â”€ train.py               # Script de treinamento
```

## ğŸ› ï¸ Preparando o Ambiente

### Passos para configurar o ambiente de **InferÃªncia** e **Treinamento**:
> Nota: inferÃªncia e treinamento devem possuir ambientes separados, eu sÃ³ testei assim e nÃ£o sei se funciona um ambiente com todas as dependÃªncias. **Tive muitos problemas com dependÃªncias por isso fiz assim**. Para cada um, vocÃª deve:

1. **Criar ambiente Conda** (Python 3.9):
   ```bash
   conda create --name transformers-train-inference python=3.9
   ```

2. **Ativar o ambiente**:
   ```bash
   conda activate transformers-train-inference
   ```

3. **Instalar PyTorch**:
   ```bash
   pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
   ```
> Nota: pode ser tambÃ©m ``pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124``

4. **Instalar dependÃªncias** (para cada diretÃ³rio):
   - Para **InferÃªncia**:
     ```bash
     cd inference
     pip install -r requirements.txt
     ```
   - Para **Treinamento**:
     ```bash
     cd train
     pip install -r requirements.txt
     ```

## ğŸš€ Como Usar

### ğŸ”§ Treinamento

A pasta `train` contÃ©m o cÃ³digo para fazer **fine-tuning** de um modelo de detecÃ§Ã£o de objetos em um dataset customizado.

- O script principal para treinar Ã© o `train.py`.
- VocÃª pode testar o modelo treinado usando o arquivo `test-trainedModel.py`.
- Os **modelos treinados** estÃ£o na pasta `models`.
- Para explorar datasets de **PPE (Equipamento de ProteÃ§Ã£o Individual)**, acesse a pasta `datasets`.

#### ğŸ“– CustomizaÃ§Ã£o do CÃ³digo

O cÃ³digo para treinamento do modelo Ã© implementado no arquivo `train.py`, onde vocÃª pode fazer ajustes conforme necessÃ¡rio:

1. **Modelo Utilizado**:
   - O modelo padrÃ£o Ã© definido pela variÃ¡vel `model_name`:
     ```python
     model_name = "facebook/detr-resnet-50"
     ```
   - Para mudar o modelo, basta alterar o valor de `model_name` para outro modelo suportado pela biblioteca Transformers.

2. **Dataset**:
   - O dataset utilizado Ã© carregado com a funÃ§Ã£o `load_dataset`:
     ```python
     ds = load_dataset("Francesco/construction-safety-gsnvb")
     ```
   - VocÃª pode modificar a linha acima para usar seu prÃ³prio dataset. Certifique-se de que ele esteja no formato esperado pela funÃ§Ã£o.


>Nota: Para saber mais sobre como preparar seu prÃ³prio dataset customizado, confira este [guia](https://github.com/huggingface/transformers/blob/main/examples/pytorch/object-detection/README.md).

### ğŸ“¸ InferÃªncia

Na pasta `inference`, vocÃª encontrarÃ¡ dois scripts de inferÃªncia:

1. **testImage_camIP.py**: Realiza a inferÃªncia de uma **imagem estÃ¡tica** usando um modelo vindo do **Hugging Face**. Ele carrega a imagem, processa e exibe o resultado com as **bounding boxes** detectadas.
   
2. **cameraIP_RealTime.py**: Faz inferÃªncia em **tempo real** com uma cÃ¢mera IP via RTSP. Este cÃ³digo utiliza threads para capturar os frames da cÃ¢mera, aplicar o modelo de detecÃ§Ã£o de EPI e mostrar as **bounding boxes** ao vivo. Para evitar atrasos, o script usa uma fila `frame_queue = queue.Queue(maxsize=1)` e pula frames quando necessÃ¡rio para manter o display em **tempo real**.

ğŸ“¹ Veja um exemplo de saÃ­da do cÃ³digo em `output.mp4`!

## ğŸŒŸ Exemplos de Uso

- Treinamento: Use o script `train.py` para treinar um modelo com o dataset PPE.
- InferÃªncia de Imagem: Teste a inferÃªncia em uma imagem com `testImage_camIP.py`.
- InferÃªncia em Tempo Real: Rode `cameraIP_RealTime.py` para visualizar a detecÃ§Ã£o de EPIs em tempo real com sua cÃ¢mera IP.


## âš ï¸ **Em Desenvolvimento**:
- [ ] Adicionar suporte para continuar o treinamento a partir de um **checkpoint**.
- [ ] Implementar o **push** do modelo para o **Hugging Face Hub**.



## ğŸ“¢ ContribuiÃ§Ã£o

Sinta-se Ã  vontade para abrir issues, sugerir melhorias ou contribuir com este projeto! Vamos melhorar juntos! ğŸ˜Š











